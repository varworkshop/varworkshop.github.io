---
layout: page
permalink: /calls/
title: Demos and Papers
description: 
nav: true
nav_order: 2
---

### Calls

We invite submissions of extended abstracts. We encourage workshop contributions to be accompanied by a demo to be shown during the workshop. While live demosâ€”such as web-based ones or those running on hardware like phones or laptops are highly encouraged, for this first edition of the workshop, video demos will also be accepted to accommodate any challenges participants may face in transporting their demo setups or devices to the workshop. The review process will be double-blind. Participants will be asked to upload their extended abstracts (with demo plans) to CMT. 

### Topics

We invite contributions on topics relevant to the development of vision-based assistants such as, (but not limited to):
- Streaming/online vision-language models 
- Real-time activity understanding 
- Grounding of vision-language models
- Ego-centric video understanding 
- Language and robot learning

### Important Information

- **CMT for submissions:** <font color="red">[Coming soon!]</font>
- **Paper length:** Extended abstracts (4 pages) with additional pages for demo plans.
- **Dates:**
	- **Paper Submission Deadline:** May 1st, 2025
	- **Notification to Authors:** May 15th, 2025
	- **Camera-ready deadline:** June 1st, 2025

All deadlines are until 11:59 pm Pacific Standard Time (PST).


